{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color='green'>MHealth DNN Manuel</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Importing dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>343195.000000</td>\n",
       "      <td>343195.000000</td>\n",
       "      <td>343195.000000</td>\n",
       "      <td>343195.000000</td>\n",
       "      <td>343195.000000</td>\n",
       "      <td>343195.000000</td>\n",
       "      <td>343195.000000</td>\n",
       "      <td>343195.000000</td>\n",
       "      <td>343195.000000</td>\n",
       "      <td>343195.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>343195.000000</td>\n",
       "      <td>343195.000000</td>\n",
       "      <td>343195.000000</td>\n",
       "      <td>343195.000000</td>\n",
       "      <td>343195.000000</td>\n",
       "      <td>343195.000000</td>\n",
       "      <td>343195.000000</td>\n",
       "      <td>343195.000000</td>\n",
       "      <td>343195.000000</td>\n",
       "      <td>343195.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-7.485271</td>\n",
       "      <td>-0.140923</td>\n",
       "      <td>-0.938418</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>-0.008048</td>\n",
       "      <td>1.805184</td>\n",
       "      <td>-9.061487</td>\n",
       "      <td>-0.701985</td>\n",
       "      <td>0.101167</td>\n",
       "      <td>-0.549942</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.448201</td>\n",
       "      <td>-5.781446</td>\n",
       "      <td>2.381165</td>\n",
       "      <td>-0.201574</td>\n",
       "      <td>-0.410515</td>\n",
       "      <td>0.380693</td>\n",
       "      <td>-0.532629</td>\n",
       "      <td>1.422140</td>\n",
       "      <td>0.030670</td>\n",
       "      <td>6.169021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.701949</td>\n",
       "      <td>2.799380</td>\n",
       "      <td>4.611164</td>\n",
       "      <td>0.839074</td>\n",
       "      <td>0.857724</td>\n",
       "      <td>4.214175</td>\n",
       "      <td>5.200389</td>\n",
       "      <td>6.457622</td>\n",
       "      <td>0.458913</td>\n",
       "      <td>0.434721</td>\n",
       "      <td>...</td>\n",
       "      <td>5.891595</td>\n",
       "      <td>6.578371</td>\n",
       "      <td>4.177971</td>\n",
       "      <td>0.549524</td>\n",
       "      <td>0.546359</td>\n",
       "      <td>0.515658</td>\n",
       "      <td>34.216257</td>\n",
       "      <td>30.285262</td>\n",
       "      <td>82.663004</td>\n",
       "      <td>3.298902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-22.438000</td>\n",
       "      <td>-20.188000</td>\n",
       "      <td>-18.401000</td>\n",
       "      <td>-8.619600</td>\n",
       "      <td>-8.619600</td>\n",
       "      <td>-22.146000</td>\n",
       "      <td>-19.619000</td>\n",
       "      <td>-19.373000</td>\n",
       "      <td>-1.779200</td>\n",
       "      <td>-2.660400</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.345000</td>\n",
       "      <td>-18.972000</td>\n",
       "      <td>-18.238000</td>\n",
       "      <td>-1.170600</td>\n",
       "      <td>-2.256700</td>\n",
       "      <td>-1.114200</td>\n",
       "      <td>-319.030000</td>\n",
       "      <td>-358.130000</td>\n",
       "      <td>-702.570000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-9.707100</td>\n",
       "      <td>-1.294300</td>\n",
       "      <td>-3.686550</td>\n",
       "      <td>-0.213500</td>\n",
       "      <td>-0.171640</td>\n",
       "      <td>0.159875</td>\n",
       "      <td>-10.063000</td>\n",
       "      <td>-3.494350</td>\n",
       "      <td>-0.345080</td>\n",
       "      <td>-0.810510</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.013900</td>\n",
       "      <td>-9.558100</td>\n",
       "      <td>0.139070</td>\n",
       "      <td>-0.682350</td>\n",
       "      <td>-0.831620</td>\n",
       "      <td>-0.040948</td>\n",
       "      <td>-6.228350</td>\n",
       "      <td>-7.272000</td>\n",
       "      <td>-12.170000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-8.800300</td>\n",
       "      <td>-0.292570</td>\n",
       "      <td>-0.881070</td>\n",
       "      <td>-0.071167</td>\n",
       "      <td>-0.046049</td>\n",
       "      <td>1.372500</td>\n",
       "      <td>-9.597700</td>\n",
       "      <td>0.340070</td>\n",
       "      <td>0.204080</td>\n",
       "      <td>-0.688560</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.480000</td>\n",
       "      <td>-7.738900</td>\n",
       "      <td>1.819100</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.597540</td>\n",
       "      <td>0.448280</td>\n",
       "      <td>0.360740</td>\n",
       "      <td>0.353930</td>\n",
       "      <td>-0.709300</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-5.117400</td>\n",
       "      <td>0.984775</td>\n",
       "      <td>1.092650</td>\n",
       "      <td>0.163270</td>\n",
       "      <td>0.138150</td>\n",
       "      <td>2.924450</td>\n",
       "      <td>-7.549800</td>\n",
       "      <td>1.819300</td>\n",
       "      <td>0.487940</td>\n",
       "      <td>-0.487800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.539050</td>\n",
       "      <td>-2.359550</td>\n",
       "      <td>5.324750</td>\n",
       "      <td>0.278430</td>\n",
       "      <td>-0.045175</td>\n",
       "      <td>0.840520</td>\n",
       "      <td>5.224000</td>\n",
       "      <td>8.350250</td>\n",
       "      <td>10.302500</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.094000</td>\n",
       "      <td>20.927000</td>\n",
       "      <td>26.196000</td>\n",
       "      <td>8.506500</td>\n",
       "      <td>8.519100</td>\n",
       "      <td>20.024000</td>\n",
       "      <td>21.161000</td>\n",
       "      <td>25.015000</td>\n",
       "      <td>1.710600</td>\n",
       "      <td>1.752300</td>\n",
       "      <td>...</td>\n",
       "      <td>19.801000</td>\n",
       "      <td>21.965000</td>\n",
       "      <td>25.741000</td>\n",
       "      <td>1.415700</td>\n",
       "      <td>1.121100</td>\n",
       "      <td>1.528000</td>\n",
       "      <td>239.690000</td>\n",
       "      <td>335.250000</td>\n",
       "      <td>657.180000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0              1              2              3   \\\n",
       "count  343195.000000  343195.000000  343195.000000  343195.000000   \n",
       "mean       -7.485271      -0.140923      -0.938418       0.003649   \n",
       "std         5.701949       2.799380       4.611164       0.839074   \n",
       "min       -22.438000     -20.188000     -18.401000      -8.619600   \n",
       "25%        -9.707100      -1.294300      -3.686550      -0.213500   \n",
       "50%        -8.800300      -0.292570      -0.881070      -0.071167   \n",
       "75%        -5.117400       0.984775       1.092650       0.163270   \n",
       "max        19.094000      20.927000      26.196000       8.506500   \n",
       "\n",
       "                  4              5              6              7   \\\n",
       "count  343195.000000  343195.000000  343195.000000  343195.000000   \n",
       "mean       -0.008048       1.805184      -9.061487      -0.701985   \n",
       "std         0.857724       4.214175       5.200389       6.457622   \n",
       "min        -8.619600     -22.146000     -19.619000     -19.373000   \n",
       "25%        -0.171640       0.159875     -10.063000      -3.494350   \n",
       "50%        -0.046049       1.372500      -9.597700       0.340070   \n",
       "75%         0.138150       2.924450      -7.549800       1.819300   \n",
       "max         8.519100      20.024000      21.161000      25.015000   \n",
       "\n",
       "                  8              9       ...                   14  \\\n",
       "count  343195.000000  343195.000000      ...        343195.000000   \n",
       "mean        0.101167      -0.549942      ...            -3.448201   \n",
       "std         0.458913       0.434721      ...             5.891595   \n",
       "min        -1.779200      -2.660400      ...           -22.345000   \n",
       "25%        -0.345080      -0.810510      ...            -5.013900   \n",
       "50%         0.204080      -0.688560      ...            -2.480000   \n",
       "75%         0.487940      -0.487800      ...            -0.539050   \n",
       "max         1.710600       1.752300      ...            19.801000   \n",
       "\n",
       "                  15             16             17             18  \\\n",
       "count  343195.000000  343195.000000  343195.000000  343195.000000   \n",
       "mean       -5.781446       2.381165      -0.201574      -0.410515   \n",
       "std         6.578371       4.177971       0.549524       0.546359   \n",
       "min       -18.972000     -18.238000      -1.170600      -2.256700   \n",
       "25%        -9.558100       0.139070      -0.682350      -0.831620   \n",
       "50%        -7.738900       1.819100      -0.300000      -0.597540   \n",
       "75%        -2.359550       5.324750       0.278430      -0.045175   \n",
       "max        21.965000      25.741000       1.415700       1.121100   \n",
       "\n",
       "                  19             20             21             22  \\\n",
       "count  343195.000000  343195.000000  343195.000000  343195.000000   \n",
       "mean        0.380693      -0.532629       1.422140       0.030670   \n",
       "std         0.515658      34.216257      30.285262      82.663004   \n",
       "min        -1.114200    -319.030000    -358.130000    -702.570000   \n",
       "25%        -0.040948      -6.228350      -7.272000     -12.170000   \n",
       "50%         0.448280       0.360740       0.353930      -0.709300   \n",
       "75%         0.840520       5.224000       8.350250      10.302500   \n",
       "max         1.528000     239.690000     335.250000     657.180000   \n",
       "\n",
       "                  23  \n",
       "count  343195.000000  \n",
       "mean        6.169021  \n",
       "std         3.298902  \n",
       "min         1.000000  \n",
       "25%         3.000000  \n",
       "50%         6.000000  \n",
       "75%         9.000000  \n",
       "max        12.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"dataset/dataset_filtered.csv\",header=None)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Splitting the dataset into the Training set and Test set</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hemanth kumar\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X=dataset.iloc[:,:-1].values\n",
    "y=dataset.iloc[:,[-1]].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "y_test=y_test.reshape(len(y_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of instances:  343195\n",
      "Total Number of Training :  274556\n",
      "Total Number of Testing  :  68639\n",
      "Number of features       :  23\n",
      "Number of Target labels  :  12\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Number of instances: \",len(dataset))\n",
    "print(\"Total Number of Training : \",len(X_train))\n",
    "print(\"Total Number of Testing  : \",len(X_test))\n",
    "print(\"Number of features       : \",len(X_train[0]))\n",
    "print(\"Number of Target labels  : \",dataset[23].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'> One hot encoding the Target</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "y_train1 = onehotencoder.fit_transform(y_train).toarray()\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "y_test1=onehotencoder.fit_transform(y_test).toarray()\n",
    "y_train1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Feature Scaling</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Building the DNN model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Network Initialized..........\n",
      "\n",
      "Number of Training samples :       274556\n",
      "Number of Features :              23\n",
      "Available Activations :\n",
      "1.relu\n",
      "2.tanh\n",
      "3.sigmoid\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from DeepNetwork import DeepNetwork\n",
    "X_train=X_train.T\n",
    "X_test=X_test.T\n",
    "y_train1=y_train1.T\n",
    "y_test1=y_test1.T\n",
    "\n",
    "# Training the model\n",
    "n_x=len(X_train)\n",
    "af=['tanh','sigmoid']\n",
    "layer_dim=[n_x,100,50,12]\n",
    "layer_size=len(layer_dim)\n",
    "\n",
    "#Initializing Deep Network\n",
    "MyNetwork=DeepNetwork(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Training the DNN model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training the Deep Network ......\n",
      "Initiated................\n",
      "\n",
      "Network Dimension :    [23, 100, 50, 12]\n",
      "Activations :          ['tanh', 'sigmoid']\n",
      "Alpha :                0.5\n",
      "Batch Size :           25\n",
      "Epochs :               10 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10 of 10) |########################| Elapsed Time: 0:01:45 Time:  0:01:45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:\n",
      " 107.92562637840629\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.clock()\n",
    "para,J_log=MyNetwork.network(X_train,y_train1,af,layer_dim,epoch=10,batch_size=25,alpha=0.5,plot=False)\n",
    "end= time.clock()\n",
    "elapsed = (end - start)\n",
    "print(\"Elapsed time:\\n\",elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Plotting the analysis curve</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8f8BDzwcqd8Es84AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2eff92346a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 100, 50, 12]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plotting cost v/s number of iterations\n",
    "plt.title('Cost V/S Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cost')\n",
    "plt.plot(range(len(J_log)), J_log)\n",
    "plt.show()\n",
    "print(layer_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Making the predictions and evaluating the model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 274556)\n",
      "Train Accuracy Score: 97.7006512332639 %\n",
      "Test Accuracy Score: 97.44605836332114 %\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Train set results\n",
    "y_pred_train =[]\n",
    "y_pred_train_decoded=[]\n",
    "y_pred_train = MyNetwork.predict(X_train,layer_size,para,af)\n",
    "print(y_pred_train.shape)\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_train_decoded = y_pred_train.T.dot(onehotencoder.active_features_).astype(int)\n",
    "y_pred_train_decoded=y_pred_train_decoded.reshape(len(y_pred_train_decoded),1)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train,y_pred_train_decoded)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_test =[]\n",
    "y_pred_test_decoded=[]\n",
    "y_pred_test = MyNetwork.predict(X_test,layer_size,para,af)\n",
    "\n",
    "y_pred_test_decoded = y_pred_test.T.dot(onehotencoder.active_features_).astype(int)\n",
    "y_pred_test_decoded=y_pred_test_decoded.reshape(len(y_pred_test_decoded),1)\n",
    "\n",
    "accuracy_test = accuracy_score(y_test,y_pred_test_decoded)\n",
    "\n",
    "print('Train Accuracy Score:',accuracy_train*100,'%')\n",
    "print('Test Accuracy Score:',accuracy_test*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Validating the model using K-Fold Cross Validation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def k_fold_crossval(X,y,k):\n",
    "    acc=[]\n",
    "    f=[]\n",
    "    kf = KFold(n_splits=k)\n",
    "    kf.get_n_splits(X)\n",
    "    i=1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X__train, X__test = X[train_index], X[test_index]\n",
    "        y__train, y__test = y[train_index], y[test_index]\n",
    "        \n",
    "        onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "        y__train1=onehotencoder.fit_transform(y__train).toarray()\n",
    "        \n",
    "\n",
    "        para,J_log=MyNetwork.network(X__train.T,y__train1.T,af,layer_dim,epoch=10,batch_size=25,alpha=0.5,plot=False)\n",
    "        \n",
    "        # Fitting the ANN to the Training set\n",
    "\n",
    "        y_pred = MyNetwork.predict(X__test.T,layer_size,para,af)\n",
    "        \n",
    "        y_pred_decoded = y_pred.T.dot(onehotencoder.active_features_).astype(int)\n",
    "        y_pred_decoded = y_pred_decoded.reshape(len(y_pred_decoded),1)\n",
    "\n",
    "        \n",
    "        accuracy = accuracy_score(y__test,y_pred_decoded)\n",
    "        print('\\nFold '+str(i)+' Accuracy Score:',accuracy*100,'%\\n')\n",
    "        acc.append(accuracy)\n",
    "        i=i+1\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Using 10 fold validation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training the Deep Network ......\n",
      "Initiated................\n",
      "\n",
      "Network Dimension :    [23, 100, 50, 12]\n",
      "Activations :          ['tanh', 'sigmoid']\n",
      "Alpha :                0.5\n",
      "Batch Size :           25\n",
      "Epochs :               10 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10 of 10) |########################| Elapsed Time: 0:01:15 Time:  0:01:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 Accuracy Score: 97.3229895104895 %\n",
      "\n",
      "\n",
      "\n",
      "Training the Deep Network ......\n",
      "Initiated................\n",
      "\n",
      "Network Dimension :    [23, 100, 50, 12]\n",
      "Activations :          ['tanh', 'sigmoid']\n",
      "Alpha :                0.5\n",
      "Batch Size :           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10 of 10) |########################| Elapsed Time: 0:01:14 Time:  0:01:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "Epochs :               10 \n",
      "\n",
      "\n",
      "Fold 2 Accuracy Score: 97.17730186480186 %\n",
      "\n",
      "\n",
      "\n",
      "Training the Deep Network ......\n",
      "Initiated................\n",
      "\n",
      "Network Dimension :    [23, 100, 50, 12]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10 of 10) |########################| Elapsed Time: 0:01:14 Time:  0:01:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Activations :          ['tanh', 'sigmoid']\n",
      "Alpha :                0.5\n",
      "Batch Size :           25\n",
      "Epochs :               10 \n",
      "\n",
      "\n",
      "Fold 3 Accuracy Score: 97.03525641025641 %\n",
      "\n",
      "\n",
      "\n",
      "Training the Deep Network ......\n",
      "Initiated................\n",
      "\n",
      "Network Dimension :    [23, 100, 50, 12]\n",
      "Activations :          ['tanh', 'sigmoid']\n",
      "Alpha :               "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10 of 10) |########################| Elapsed Time: 0:01:19 Time:  0:01:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.5\n",
      "Batch Size :           25\n",
      "Epochs :               10 \n",
      "\n",
      "\n",
      "Fold 4 Accuracy Score: 96.90049533799534 %\n",
      "\n",
      "\n",
      "\n",
      "Training the Deep Network ......\n",
      "Initiated................\n",
      "\n",
      "Network Dimension :    [23, 100, 50, 12]\n",
      "Activations :          ['tanh', 'sigmoid']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10 of 10) |########################| Elapsed Time: 0:01:13 Time:  0:01:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha :                0.5\n",
      "Batch Size :           25\n",
      "Epochs :               10 \n",
      "\n",
      "\n",
      "Fold 5 Accuracy Score: 97.25014568764568 %\n",
      "\n",
      "\n",
      "\n",
      "Training the Deep Network ......\n",
      "Initiated................\n",
      "\n",
      "Network Dimension :    [23, 100, 50, 12]\n",
      "Activations :          ['tanh', 'sigmoid']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10 of 10) |########################| Elapsed Time: 0:01:12 Time:  0:01:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alpha :                0.5\n",
      "Batch Size :           25\n",
      "Epochs :               10 \n",
      "\n",
      "\n",
      "Fold 6 Accuracy Score: 97.38490675990677 %\n",
      "\n",
      "\n",
      "\n",
      "Training the Deep Network ......\n",
      "Initiated................\n",
      "\n",
      "Network Dimension :    [23, 100, 50, 12]\n",
      "Activations :         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10 of 10) |########################| Elapsed Time: 0:01:12 Time:  0:01:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ['tanh', 'sigmoid']\n",
      "Alpha :                0.5\n",
      "Batch Size :           25\n",
      "Epochs :               10 \n",
      "\n",
      "\n",
      "Fold 7 Accuracy Score: 97.08249863412858 %\n",
      "\n",
      "\n",
      "\n",
      "Training the Deep Network ......\n",
      "Initiated................\n",
      "\n",
      "Network Dimension :    [23, 100, 50, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10 of 10) |########################| Elapsed Time: 0:01:11 Time:  0:01:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations :          ['tanh', 'sigmoid']\n",
      "Alpha :                0.5\n",
      "Batch Size :           25\n",
      "Epochs :               10 \n",
      "\n",
      "\n",
      "Fold 8 Accuracy Score: 96.99144053906392 %\n",
      "\n",
      "\n",
      "\n",
      "Training the Deep Network ......\n",
      "Initiated................\n",
      "\n",
      "Network Dimension :    [23, 100, 50, 12]\n",
      "Activations :         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10 of 10) |########################| Elapsed Time: 0:01:10 Time:  0:01:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ['tanh', 'sigmoid']\n",
      "Alpha :                0.5\n",
      "Batch Size :           25\n",
      "Epochs :               10 \n",
      "\n",
      "\n",
      "Fold 9 Accuracy Score: 97.17719905299582 %\n",
      "\n",
      "\n",
      "\n",
      "Training the Deep Network ......\n",
      "Initiated................\n",
      "\n",
      "Network Dimension :    [23, 100, 50, 12]\n",
      "Activations :          ['tanh', 'sigmoid']\n",
      "Alpha :                0.5\n",
      "Batch Size :           25\n",
      "Epochs :               10 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10 of 10) |########################| Elapsed Time: 0:01:13 Time:  0:01:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 10 Accuracy Score: 96.62356583500274 %\n",
      "\n",
      "K fold cross validation Accuracy:  0.9709457996322868\n"
     ]
    }
   ],
   "source": [
    "acc=k_fold_crossval(X_train.T,y_train,10)\n",
    "print(\"K fold cross validation Accuracy: \",np.mean(np.array(acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K fold cross validation Accuracy:  97.09457996322868 %\n"
     ]
    }
   ],
   "source": [
    "print(\"K fold cross validation Accuracy: \",np.mean(np.array(acc))*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
